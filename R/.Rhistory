load('techno_topic_models.Rdata')
setwd("/Users/alexisperrier/amcp/upem-topic-modeling/R")
load('techno_topic_models.Rdata')
fit <- stm(out$documents, out$vocab, 0,
prevalence  =~ journal + rubrique,
data        = meta,
reportevery = 10,
max.em.its  = 100,
emtol       = 1.0e-4,
init.type   = "Spectral",
seed        = 1)
library('stringr')
library('stm')
library('stmBrowser')
library('wordcloud')
library('igraph')
library('geometry')
library('Rtsne')
library('SnowballC')
library('GetoptLong')
fit <- stm(out$documents, out$vocab, 0,
prevalence  =~ journal + rubrique,
data        = meta,
reportevery = 10,
max.em.its  = 100,
emtol       = 1.0e-4,
init.type   = "Spectral",
seed        = 1)
fit_0 <-fit
save.image('techno_topic_models.Rdata')
?prepDocuments
topicQuality(model=fit, documents=out$documents, main='Topic Quality',bty="n")
data_path <- '/Users/alexisperrier/amcp/upem-topic-modeling/data/'
input_file    <- qq("@{data_path}echantillon_god_emperor_trump.csv")
qqcat("Load data from @{input_file}")
df        <- read.csv(input_file)
dim(df)
df[1:2,]
processed <- textProcessor(df[,'content'],
lowercase        = TRUE,
removestopwords  = TRUE,
removenumbers    = TRUE,
removepunctuation = TRUE,
wordLengths      = c(3,Inf),
striphtml        = TRUE,
stem             = FALSE,
metadata         = df)
processed <- textProcessor(df[,'message'],
lowercase        = TRUE,
removestopwords  = TRUE,
removenumbers    = TRUE,
removepunctuation = TRUE,
wordLengths      = c(3,Inf),
striphtml        = TRUE,
stem             = FALSE,
metadata         = df)
thresh.lower  <- 50
out   <- prepDocuments(processed$documents, processed$vocab, processed$meta,
lower.thresh = thresh.lower)
meta  <- out$meta
n_topics = seq(from = 20, to = 50, by = 5)
gridsearch <- searchK(out$documents, out$vocab,
K = n_topics,
# prevalence  =~ journal+ rubrique ,
reportevery = 10,
# max.em.its = maxemits,
emtol       = 1.5e-4,
data = meta)
library('stringr')
library('stm')
library('stmBrowser')
library('wordcloud')
library('igraph')
library('geometry')
library('Rtsne')
library('SnowballC')
library('GetoptLong')
qq.options("cat_prefix" = function(x) format(Sys.time(), "\n[%H:%M:%S] "))
setwd("/Users/alexisperrier/amcp/upem-topic-modeling/R")
data_path <- '/Users/alexisperrier/amcp/upem-topic-modeling/data/'
input_file    <- qq("@{data_path}echantillon_god_emperor_trump.csv")
qqcat("Load data from @{input_file}")
df        <- read.csv(input_file)
dim(df)
df[1:2,]
processed <- textProcessor(df[,'message'],
lowercase        = TRUE,
removestopwords  = TRUE,
removenumbers    = TRUE,
removepunctuation = TRUE,
wordLengths      = c(3,Inf),
striphtml        = TRUE,
stem             = FALSE,
metadata         = df)
thresh.lower  <- 50
out   <- prepDocuments(processed$documents, processed$vocab, processed$meta,
lower.thresh = thresh.lower)
meta  <- out$meta
processed$vocab
processed$documents
processed$meta
out   <- prepDocuments(processed$documents, processed$vocab, processed$meta,
lower.thresh = thresh.lower)
input_file    <- qq("@{data_path}echantillon_god_emperor_trump.csv")
df        <- read.csv(input_file)
df[1:2,]
processed <- textProcessor(df[,'message'],
lowercase        = TRUE,
removestopwords  = TRUE,
removenumbers    = TRUE,
removepunctuation = TRUE,
wordLengths      = c(3,Inf),
striphtml        = TRUE,
stem             = FALSE,
metadata         = df)
out   <- prepDocuments(processed$documents, processed$vocab, processed$meta,
lower.thresh = thresh.lower)
meta  <- out$meta
n_topics = seq(from = 20, to = 50, by = 5)
gridsearch <- searchK(out$documents, out$vocab,
K = n_topics,
# prevalence  =~ journal+ rubrique ,
reportevery = 10,
# max.em.its = maxemits,
emtol       = 1.5e-4,
data = meta)
plot(gridsearch)
print(gridsearch)
plot(gridsearch$results$exclus, gridsearch$results$semcoh)
text(gridsearch$results$exclus, gridsearch$results$semcoh, labels=gridsearch$results$K, cex= 0.7, pos = 2)
plot(gridsearch$results$semcoh, gridsearch$results$exclus)
text(gridsearch$results$semcoh, gridsearch$results$exclus, labels=gridsearch$results$K, cex= 0.7, pos = 2)
fit <- stm(out$documents, out$vocab, 25,
# prevalence  =~ journal + rubrique,
data        = meta,
reportevery = 10,
max.em.its  = 100,
emtol       = 1.0e-4,
init.type   = "Spectral",
seed        = 1)
fit_25 <-fit
findTopic(fit, c("america"), n = 20)
cloud(fit, 14)
save.image('echantillon_god_emperor_trump.Rdata')
topic_corr = topicCorr(fit, method = "simple", cutoff = 0.1)
plot(topic_corr, topics = c())
?plt.STM
?plot.STM
plot.STM( fit,
type = "perspectives",
labeltype= 'frex',
# topics = c(5,2),
main= 'Importance des topics',
n = 10
)
plot.STM( fit,
type = "perspectives",
labeltype= 'frex',
topics = c(5,2),
main= 'Importance des topics',
n = 10
)
plot.STM( fit,
type = "summary",
labeltype= 'frex',
topics = c(5,2),
main= 'Importance des topics',
n = 10
)
plot.STM( fit,
type = "summary",
labeltype= 'frex',
# topics = c(5,2),
main= 'Importance des topics',
n = 10
)
topicQuality(model=fit, documents=out$documents, main='Topic Quality',bty="n")
plot(fit, labeltype=c("frex"), main = 'Topic Most Frequent Words',bty="n", n= 5)
cloud(fit, 3)
findThoughts(fit, texts = out$meta$content, topics = 14, n = 3 )
findThoughts(fit, texts = out$meta$message, topics = 14, n = 3 )
topicQuality(model=fit, documents=out$documents, main='Topic Quality',bty="n")
plot(fit, labeltype=c("frex"), main = 'Topic Most Frequent Words',bty="n", n= 5)
topicQuality(model=fit, documents=out$documents, main='Topic Quality',bty="n")
cloud(fit, 14)
plot(fit, labeltype=c("frex"), main = 'Topic Most Frequent Words',bty="n", n= 5)
print( labelTopics(fit,14, n=10) )
findThoughts(fit, texts = out$meta$message, topics = 14, n = 3 )
findThoughts(fit, texts = out$meta$message, topics = 14, n = 5 )
findTopic(fit, c("mexico"), n = 20)
findTopic(fit, c("wall"), n = 20)
findTopic(fit, c("china"), n = 20)
findTopic(fit, c("pussy"), n = 20)
findThoughts(fit, texts = out$meta$message, topics = 15, n = 5 )
findThoughts(fit, texts = out$meta$message, topics = 14, n = 5 )
cloud(fit, 14)
plot(fit, labeltype=c("Highest Prob"), main = 'Topic Most Frequent Words',bty="n", n= 5)
plot(fit, labeltype=c("prob"), main = 'Topic Most Frequent Words',bty="n", n= 5)
cloud(fit, 6)
setwd("/Users/alexisperrier/amcp/upem-topic-modeling/R")
data_path <- '/Users/alexisperrier/amcp/upem-topic-modeling/data/'
input_file    <- qq("@{data_path}tags_sent_tokens_reduced.csv")
qqcat("Load data from @{input_file}")
df        <- read.csv(input_file)
dim(df)
setwd("~/amcp/memewar/data")
setwd("~/amcp/memewar")
load('data/topics_01.RData')
print(labelTopics(fit, n=10))
topicQuality(model=fit, documents=docs, main='Topic Quality',bty="n")
plot(fit, labeltype=c("frex"), main = 'Topic Most Frequent Words',bty="n")
colnames(df)
plot(gridsearch)
library('stringr')
library('stm')
library('stmBrowser')
library('wordcloud')
library('igraph')
library('geometry')
library('Rtsne')
library('SnowballC')
library('GetoptLong')
qq.options("cat_prefix" = function(x) format(Sys.time(), "\n[%H:%M:%S] "))
setwd("/Users/alexisperrier/amcp/upem-topic-modeling/R")
data_path <- '/Users/alexisperrier/amcp/upem-topic-modeling/data/'
input_file    <- qq("@{data_path}tags_sent_tokens_reduced.csv")
qqcat("Load data from @{input_file}")
df        <- read.csv(input_file)
dim(df)
df[1:2,]
processed <- textProcessor(df[,'message'],
lowercase        = FALSE,
removestopwords  = FALSE,
removenumbers    = FALSE,
removepunctuation = FALSE,
wordLengths      = c(3,Inf),
striphtml        = FALSE,
stem             = FALSE,
metadata         = df)
processed <- textProcessor(df[,'sent_tokens'],
lowercase        = FALSE,
removestopwords  = FALSE,
removenumbers    = FALSE,
removepunctuation = FALSE,
wordLengths      = c(3,Inf),
striphtml        = FALSE,
stem             = FALSE,
metadata         = df)
thresh.lower  <- 50
out   <- prepDocuments(processed$documents, processed$vocab, processed$meta,
lower.thresh = thresh.lower)
colnames(df)
meta  <- out$meta
meta$christian  <- as.factor(meta$memewar)
meta$islam  <- as.factor(meta$nazi)
meta$judaism  <- as.factor(meta$europe)
df        <- read.csv(input_file)
dim(df)
library('stringr')
library('stm')
library('stmBrowser')
library('wordcloud')
library('igraph')
library('geometry')
library('Rtsne')
library('SnowballC')
library('GetoptLong')
qq.options("cat_prefix" = function(x) format(Sys.time(), "\n[%H:%M:%S] "))
setwd("/Users/alexisperrier/amcp/upem-topic-modeling/R")
data_path <- '/Users/alexisperrier/amcp/upem-topic-modeling/data/'
input_file    <- qq("@{data_path}tags_sent_tokens_reduced.csv")
qqcat("Load data from @{input_file}")
df        <- read.csv(input_file)
dim(df)
df[1:2,]
processed <- textProcessor(df[,'sent_tokens'],
lowercase        = FALSE,
removestopwords  = FALSE,
removenumbers    = FALSE,
removepunctuation = FALSE,
wordLengths      = c(3,Inf),
striphtml        = FALSE,
stem             = FALSE,
metadata         = df)
data_path <- '/Users/alexisperrier/amcp/upem-topic-modeling/data/'
input_file    <- qq("@{data_path}fbget_stm_ready_full_01.csv")
df        <- read.csv(input_file)
dim(df)
df[1:2,]
qqcat("pre processing\n")
processed <- textProcessor(df[,'sent_tokens'],
lowercase        = FALSE,
removestopwords  = FALSE,
removenumbers    = FALSE,
removepunctuation = FALSE,
wordLengths      = c(3,Inf),
striphtml        = FALSE,
stem             = FALSE,
metadata         = df)
thresh.lower  <- 50
out   <- prepDocuments(processed$documents, processed$vocab, processed$meta,
lower.thresh = thresh.lower)
meta  <- out$meta
meta$christian  <- as.factor(meta$memewar)
meta$islam  <- as.factor(meta$nazi)
meta$judaism  <- as.factor(meta$europe)
meta$memewar  <- as.factor(meta$memewar)
meta$nazi     <- as.factor(meta$nazi)
meta$europe  <- as.factor(meta$europe)
n_topics = seq(from = 20, to = 60, by = 3)
gridsearch <- searchK(out$documents, out$vocab,
K = n_topics,
prevalence  =~ memewar + nazi + europe ,
reportevery = 10,
# max.em.its = maxemits,
emtol       = 1.5e-4,
data = meta)
plot(gridsearch)
print(gridsearch)
plot(gridsearch$results$exclus, gridsearch$results$semcoh)
text(gridsearch$results$exclus, gridsearch$results$semcoh, labels=gridsearch$results$K, cex= 0.7, pos = 2)
gridsearch_fbget <- gridsearch
fit <- stm(out$documents, out$vocab, 25,
prevalence  =~ memewar + nazi + europe ,
data        = meta,
reportevery = 10,
# max.em.its  = 100,
emtol       = 1.0e-4,
init.type   = "Spectral",
seed        = 1)
fit_fbget_25 <-fit
print( labelTopics(fit, n=10) )
plot(fit, labeltype=c("prob"), main = 'Topic Most Frequent Words',bty="n", n= 5)
topic_corr = topicCorr(fit, method = "simple", cutoff = 0.1)
plot(topic_corr, topics = c())
plot.STM( fit,
type = "perspectives",
labeltype= 'frex',
topics = c(1,12),
main= 'Comparaison entre 2 topics',
n = 5
)
topicQuality(model=fit, documents=out$documents, main='Topic Quality',bty="n")
findThoughts(fit, texts = out$meta$message, topics = 8, n = 5 )
findThoughts(fit, texts = out$meta$message, topics = 14, n = 5 )
findThoughts(fit, texts = out$meta$message, topics = 6, n = 5 )
findTopic(fit, c("pussy"), n = 20)
save.image('tags_sent_tokens_reduced.Rdata')
save.image('fbget_stm_ready_full_01.Rdata')
fit <- stm(out$documents, out$vocab, 0,
prevalence  =~ memewar + nazi + europe ,
data        = meta,
reportevery = 10,
# max.em.its  = 100,
emtol       = 1.0e-4,
init.type   = "Spectral",
seed        = 1)
fit_fbget_0 <-fit
topic_corr = topicCorr(fit, method = "simple", cutoff = 0.1)
plot(topic_corr, topics = c())
topicQuality(model=fit, documents=out$documents, main='Topic Quality',bty="n")
cloud(fit, 8)
save.image('fbget_stm_ready_full_01.Rdata')
load('techno_topic_models.Rdata')
fit <- fit_20
print( labelTopics(fit, n=10) )
plot.STM( fit,
type = "summary",
labeltype= 'frex',
# topics = c(24,42),
main= 'Importance des topics',
n = 10
)
topic_corr = topicCorr(fit, method = "simple", cutoff = 0.1)
plot(topic_corr, topics = c())
topicQuality(model=fit, documents=out$documents, main='Topic Quality',bty="n")
cloud(fit, 6)
load("~/amcp/upem-topic-modeling/R/fbget_stm_ready_full_01.Rdata")
fit <- fit_fbget_0
print( labelTopics(fit, n=10) )
plot(gridsearch)
print(gridsearch)
plot(gridsearch$results$exclus, gridsearch$results$semcoh)
text(gridsearch$results$exclus, gridsearch$results$semcoh, labels=gridsearch$results$K, cex= 0.7, pos = 2)
plot.STM( fit,
type = "summary",
labeltype= 'frex',
# topics = c(24,42),
main= 'Importance des topics',
n = 10
)
load("~/amcp/upem-topic-modeling/R/fbget_stm_ready_full_01.Rdata")
fit <- fit_fbget_25
plot.STM( fit,
type = "summary",
labeltype= 'frex',
# topics = c(24,42),
main= 'Importance des topics',
n = 10
)
colnames(df)
stmBrowser(fit, data=out$meta,  c("memewar", "nazi","europe"), text="display_message", labeltype='frex', n = 4)
?stmBrowser
stmBrowser(fit, data=out$meta,  c("memewar", "nazi","europe"), text="display_message", labeltype='frex', n = 500)
fit <- fit_fbget_0
stmBrowser(fit, data=out$meta,  c("memewar", "nazi","europe"), text="display_message", labeltype='frex', n = 1000)
save.image('fbget_stm_ready_full_01.Rdata')
?setwd
setwd("/Users/alexisperrier/amcp/upem-topic-modeling/R")
getwd()
library('stringr')
2+2
library('stringr')
library('stm')
library('stmBrowser')
library('wordcloud')
library('igraph')
library('geometry')
library('Rtsne')
library('SnowballC')
library('GetoptLong')
qq.options("cat_prefix" = function(x) format(Sys.time(), "\n[%H:%M:%S] "))
setwd("/Users/alexisperrier/amcp/upem-topic-modeling/R")
input_file    <- qq("@{data_path}techno.csv")
qqcat("Load data from @{input_file}")
setwd("/Users/alexisperrier/amcp/upem-topic-modeling/R")
data_path <- '/Users/alexisperrier/amcp/upem-topic-modeling/data/'
input_file    <- qq("@{data_path}techno.csv")
qqcat("Load data from @{input_file}")
df  <- read.csv(input_file)
dim(df)
df[1:2,]
qqcat("pre processing\n")
processed <- textProcessor(df[,'content'],
lowercase        = TRUE,
removestopwords  = TRUE,
removenumbers    = TRUE,
removepunctuation = TRUE,
wordLengths      = c(3,Inf),
striphtml        = TRUE,
stem             = FALSE,
metadata         = df)
processed$vocab
processed$documents
out   <- prepDocuments(processed$documents, processed$vocab, processed$meta,
lower.thresh = thresh.lower)
thresh.lower  <- 50
out   <- prepDocuments(processed$documents, processed$vocab, processed$meta,
lower.thresh = thresh.lower)
meta  <- out$meta
meta$journal  <- as.factor(meta$journal)
meta$rubrique <- as.factor(meta$rubrique)
?stm
meta  <- out$meta
meta$journal  <- as.factor(meta$journal)
meta$rubrique <- as.factor(meta$rubrique)
fit <- stm(out$documents, out$vocab, 0,
prevalence  =~ journal + rubrique,
data        = meta,
reportevery = 10,
# max.em.its  = 100,
emtol       = 1.5e-4,
init.type   = "Spectral",
seed        = 1)
qqcat("stm done\n")
print( labelTopics(fit, n=5) )
print( labelTopics(fit, n=10) )
plot.STM( fit,
type = "summary",
labeltype= 'frex',
main= 'Importance des topics',
n = 10
)
topicQuality(model=fit, documents=out$documents, main='Topic Quality',bty="n")
print( labelTopics(fit, n=10, c(1,13)) )
topic_corr = topicCorr(fit, method = "simple", cutoff = 0.1)
plot(topic_corr, topics = c())
cloud(fit, 1)
cloud(fit, 13)
stmBrowser(fit, data=out$meta, c("journal"), text="content", labeltype='frex', n = 900)
findTopic(fit, c("cars"), n = 20)
findTopic(fit, c("autonomous"), n = 20)
cloud(fit, 17)
load('techno_topic_models.Rdata')
n_topics
n_topics = seq(from = 20, to = 50, by = 5)
n_topics
plot(gridsearch)
plot(gridsearch$results$exclus, gridsearch$results$semcoh)
text(gridsearch$results$exclus, gridsearch$results$semcoh, labels=gridsearch$results$K, cex= 0.7, pos = 2)
fit <- fit_20
print( labelTopics(fit, n=8) )
stmBrowser(fit, data=out$meta, c("journal"), text="content", labeltype='frex', n = 900)
findThoughts(fit, texts = out$meta$content, topics = 19, n = 3 )
cloud(fit, 14)
cloud(fit, 14)
plot.STM( fit,
type = "summary",
labeltype= 'frex',
main= 'Importance des topics',
n = 10
)
fit$theta
plot(gridsearch$results$exclus, gridsearch$results$semcoh)
text(gridsearch$results$exclus, gridsearch$results$semcoh, labels=gridsearch$results$K, cex= 0.7, pos = 2)
plot(gridsearch)
print(gridsearch)
load('fbget_stm_ready_full_01.Rdata')
stmBrowser(fit, data=out$meta,  c("memewar", "nazi","europe"), text="display_message", labeltype='frex', n = 4)
stmBrowser(fit, data=out$meta,  c("memewar", "nazi","europe"), text="display_message", labeltype='frex', n = 1000)
