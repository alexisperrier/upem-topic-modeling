var data = [{"id":1,"body":"<div id='rss wrap'>\n<figure class='intro image intro left'><img src='https://cdn.arstechnica.net/wp content/uploads/2017/05/GettyImages 622951580 800x534.jpg'><p class='caption' style='font size:0.8em'><a href='https://cdn.arstechnica.net/wp content/uploads/2017/05/GettyImages 622951580.jpg' class='enlarge link' data height='683' data width='1024'>Enlarge</a> <span class='sep'>/</span> President Trump\u2019s executive order on cybersecurity is built on the orders and policies of his predecessor, and is almost entirely apolitical. (credit: <a rel='nofollow' class='caption link' href='http://www.gettyimages.com/collections/wapost'>Jabin Botsford/The Washington Post via Getty Images</a>)</p>  </figure><div><a name='page 1'></a></div>\n<p>Last week, amidst the whirlwind surrounding the firing of FBI Director James Comey, President Donald Trump signed his long promised executive order on federal government cybersecurity. While many of the other orders issued by Trump have been politically fraught, this one is not; it's possibly the least controversial document to be adorned with the president's signature since his inauguration.</p>\n<p>In fact, aside from some of the more Trumpian language in the order, this Executive Order could have easily been issued by the Obama administration. That's because it largely is based on policies and procedures that were spearheaded by President Obama's staff.</p>\n<p>'My initial reaction to the order is, 'this is great,'' former National Security Council Director for Cybersecurity Policy Ben Flatgard told Ars. 'Trump just endorsed Barack Obama's cybersecurity policy.' Flatgard was one of the principal authors of the Obama administration's <a href='https://obamawhitehouse.archives.gov/the press office/2016/02/09/fact sheet cybersecurity national action plan'>Cyber National Action Plan (CNAP)</a>, published in February of 2016.</p>\n</div><p><a href='https://arstechnica.com/tech policy/2017/05/the text and subtext of trumps cyber executive order/#p3'>Read 29 remaining paragraphs</a> | <a href='https://arstechnica.com/tech policy/2017/05/the text and subtext of trumps cyber executive order/?comments=1'>Comments</a></p>","journal":"arstechnica","Topic 1":0.000144013435295745,"Topic 2":0.000772091839369528,"Topic 3":0.00307694927451547,"Topic 4":1.07457308741005e-05,"Topic 5":2.29722781995347e-05,"Topic 6":0.000337027034591651,"Topic 7":2.4646645964231e-05,"Topic 8":6.34954522181968e-05,"Topic 9":6.85892249116088e-05,"Topic 10":5.07550024405357e-05,"Topic 11":0.00372074505072422,"Topic 12":0.000168670522018315,"Topic 13":5.72927822342446e-05,"Topic 14":4.86541317640216e-06,"Topic 15":0.00115101904482997,"Topic 16":8.11993534315473e-05,"Topic 17":4.89370264819727e-05,"Topic 18":2.09317953365271e-05,"Topic 19":0.000109728127902679,"Topic 20":0.000151961651275185,"Topic 21":5.91346375985314e-05,"Topic 22":0.00158972437075724,"Topic 23":0.000140151360454992,"Topic 24":0.000985189994980176,"Topic 25":0.00138746915236147,"Topic 26":3.15861859684869e-05,"Topic 27":0.000219013951853801,"Topic 28":0.00286687873739125,"Topic 29":0.00414379679655251,"Topic 30":1.2913591920244e-05,"Topic 31":2.50949709651807e-05,"Topic 32":4.36266483513874e-06,"Topic 33":3.23687058525931e-05,"Topic 34":0.000307457592401777,"Topic 35":0.00067818261718769,"Topic 36":0.000897414500192279,"Topic 37":0.000392737479847351,"Topic 38":0.000734175653263844,"Topic 39":1.6752249827195e-05,"Topic 40":0.799647437818732,"Topic 41":0.00640729867463091,"Topic 42":0.0016247908710275,"Topic 43":0.000423335459119072,"Topic 44":0.00370115669203317,"Topic 45":7.76465573664952e-06,"Topic 46":0.150180660778705,"Topic 47":5.17263813817712e-05,"Topic 48":0.00111978130246233,"Topic 49":9.60356991457229e-05,"Topic 50":7.23117749115866e-05,"Topic 51":8.25885362600051e-06,"Topic 52":6.46122745791069e-06,"Topic 53":3.00479287631407e-05,"Topic 54":0.00160866785708296,"Topic 55":0.000494139491127456,"Topic 56":4.22659991252883e-05,"Topic 57":0.000121897180982324,"Topic 58":0.00017313400590795,"Topic 59":1.86098963494695e-05,"Topic 60":7.77318370910481e-05,"Topic 61":0.000110771672093919,"Topic 62":0.00936467204250358},{"id":2,"body":"<?xml version='1.0' encoding='UTF 8'?><html>\n<body>This robotic foam sprayer can make you most of an igloo in 13.5 hours flat<figure>\n<img src='http://spectrum.ieee.org/image/Mjg5MjcxMQ.jpeg'/>\n<figcaption>Photo: Science Robotics</figcaption>\n<figcaption>This construction robot can make you a foam igloo in 13.5 hours flat.</figcaption>\n</figure>\n<div>\n<p>Construction seems like an industry that, were I still living in Silicon Valley, I would be tempted to call \u201cripe for disruption.\u201d Researchers at the MIT Media Lab agree, pointing out in a paper just published in <em>Science Robotics</em> that construction \u201crelies on traditional fabrication technologies that are dangerous, slow, and energy intensive.\u201d Hey, sounds like a job for some robots, right?</p>\n<p>The Media Lab\u2019s paper introduces the Digital Construction Platform (DCP), which is \u201can automated construction system capable of customized on site fabrication of architectural scale structures.\u201d In other words, it\u2019s a robot arm that uses additive construction techniques to build large structures safely, quickly, and even (in some cases) renewably.</p>\n<p class='jwcode'>\n<script src='//content.jwplatform.com/players/X47ajgYb 7pFgM9ap.js' class='jwembed'/>\n</p>\n<p>Some of the most interesting robots we\u2019ve seen over recent years have <a shape='rect' href='http://spectrum.ieee.org/automaton/robotics/diy/watch this robot build a ramp by randomly flinging 3600 toothpicks'>used additive manufacturing to build small scale structures</a>, or even <a shape='rect' href='http://spectrum.ieee.org/automaton/robotics/diy/watch this robot build other robots out of spray foam'>build themselves</a>. Large scale robotic construction has also been an area of active research, but none of the concepts or prototypes have really panned out. There have been <a shape='rect' href='http://spectrum.ieee.org/automaton/robotics/industrial robots/robots do construction with brick and concrete'>bricklaying robots, gantry robots that can 3D print buildings out of concrete</a>, and even <a shape='rect' href='http://spectrum.ieee.org/automaton/robotics/diy/video watch flying robots build a 6 meter tower'>drones that build walls by transporting one brick at a time</a>. The most practical of these solutions are probably the gantry based 3D printers, but the big disadvantage of them is that they work best if you set them up somewhere and let them churn out prefabricated buildings.</p>\n<figure role='img' class='xlrg'>\n<img src='http://spectrum.ieee.org/image/Mjg5MjU0OQ.jpeg' alt='Robot'/>\n<figcaption class='hi cap'>\n  Photo: Science Robotics\n </figcaption>\n</figure>\n<p>MIT Media Lab\u2019s Digital Construction Platform (DCP), on the other hand, is mobile (with a top speed of 0.5 meters per second) and self contained. It\u2019s battery powered (with a few solar panels on it and an option for more to be attached), so it can potentially run forever, or as long as you have sun. Otherwise, the DCP mimics much of the functionality of a 3D building printer: It has a long reach, giving it a maximum printable volume of 2,786 cubic meters. The robot itself is made out of two arms, modeled loosely on a human: There\u2019s a big long arm with 4 degrees of freedom (DoF) that does all the gross motions, and one small, dexterous 6 DoF Kuka arm that takes care of fine motions like our hands and fingers would. Put it all together, and the total system cost comes to US $244,500, which is really not that bad.</p>\n<p>The construction technique that the DCP uses is straightforward: There\u2019s a sprayer at the end of the small arm that combines two chemicals into a liquid polyurethane foam that rapidly expands and <span>hardens</span>. You can program the DCP to print anything you like, but in the demo in the video above it\u2019s whipping up a 14.6 meter wide, 3.7 meter tall hemispherical open dome at a rate of 1.728 cubic meters per hour, printing layer on top of layer. Rather than build the entire structure out of foam, the DCP is actually creating a concrete formwork: Two foam walls, one nested inside the other, with a space in the middle that you can pour concrete into to make a more permanent and resilient structure (or backfill it with dirt or anything else in a pinch), after dropping in plumbing and electrical and stuff. Leaving the foam in place after you do this just adds to the insulation of the resulting building. But even as is, with just foam and no concrete, the structure is still strong enough for a well fed grad student to play hopscotch on top of it:</p>\n<figure role='img' class='xlrg'>\n<img src='http://spectrum.ieee.org/image/Mjg5MjU1OA.jpeg' alt='Robot'/>\n<figcaption class='hi cap'>\n  Photo: Science Robotics\n </figcaption>\n</figure>\n<p>Because the foam dries so quickly, it really is possible to make a dome out of it, since successive layers don't have to be directly on top of each other. They can even be offset by 90 degrees, enabling flat roofs or unsupported shelves and benches. When additional support is required, the researchers have been experimenting with autonomously embedding rebar, and also with chains that have been autonomously welded into rigid shapes, as shown in the concept below: </p>\n<figure role='img' class='xlrg'>\n<img src='http://spectrum.ieee.org/image/Mjg5MjU1OQ.jpeg' alt='DCP'/>\n<figcaption class='hi cap'>\n  Image: Science Robotics\n </figcaption>\n</figure>\n<p>In order to be able to build on demand structures anywhere, the DCP needs two things: power and materials. Power is a hassle, but there\u2019s no real technological barrier, since (hypothetically) you can just add as many solar panels and batteries as necessary to keep the robot powered up and running. Building materials are a bit more of a challenge, because you can\u2019t easily make spray foam ingredients from scratch. Fortunately, spray foam isn\u2019t the only useful building material, even if it might be the most optimal one for these purposes. The researchers have also successfully done some preliminary experimentation with electro sintered powdered glass, thermally deposited ice, and compressed earth containing gravel and hay fibers. Depending on where you want to build stuff, all of these materials are potentially available locally and in bulk.</p>\n<figure role='img' class='xlrg'>\n<img src='http://spectrum.ieee.org/image/Mjg5MjU2MA.jpeg' alt='DCP'/>\n<figcaption class='hi cap'>\n  Image: Science Robotics\n </figcaption>\n</figure>\n<p>This is a very compelling idea\u2014as long as you supply sun and raw materials, these robots could built structures quickly, autonomously, and at very low cost, which are not three characteristics that you usually find together. The researchers have imagined several scenarios, including fabricating ice structures in polar environments and creating fractal structures out of sand in deserts to be later immersed in the ocean to provide coral reef habitat.</p>\n<figure role='img' class='xlrg'>\n<img src='http://spectrum.ieee.org/image/Mjg5MjU2MQ.jpeg' alt='DCP'/>\n<figcaption class='hi cap'>\n  Image: Science Robotics\n </figcaption>\n</figure>\n<p>At this point, it seems as though robots like these would be most valuable after natural disasters or during refugee crises, when you need to be able to create an enormous amount of housing in low infrastructure areas very quickly and cheaply. Whether or not such robots will prove to be more practical than other solutions for rapid construction in the near term remains to be seen; as with many robotics applications, humans are still the cheapest and most efficient way to do things. </p>\n<p>\u201cToward Site Specific and Self Sufficient Robotic Fabrication on Architectural Scales,\u201d by Steven J. Keating, Julian C. Leland, Levi Cai, and Neri Oxman from the MIT Media Lab, was published in <em>Science Robotics</em>.</p>\n<p>[ <em>\n<a shape='rect' href='http://robotics.sciencemag.org/content/2/5/eaam8986'>Science Robotics</a>\n</em> ]</p>\n</div>\n</body>\n</html>","journal":"ieee","Topic 1":0.000120199649136146,"Topic 2":0.000955183593790907,"Topic 3":0.000417744867025935,"Topic 4":0.00360372099953586,"Topic 5":0.0307823338465969,"Topic 6":0.000147067241331837,"Topic 7":0.00344808009336456,"Topic 8":0.000571975336318597,"Topic 9":0.000110290671963438,"Topic 10":0.000368352215174223,"Topic 11":0.00182150871529515,"Topic 12":0.00174585406246912,"Topic 13":0.0340486884687468,"Topic 14":0.02133352826178,"Topic 15":0.00202050146125675,"Topic 16":0.00202438511651748,"Topic 17":0.000277921065809219,"Topic 18":0.00399578833483973,"Topic 19":0.00118266002853515,"Topic 20":0.000440362525294217,"Topic 21":0.00925107695827959,"Topic 22":0.000166479815560029,"Topic 23":0.00183248109869244,"Topic 24":0.00470904709090768,"Topic 25":0.000253678820918951,"Topic 26":0.0226692095831498,"Topic 27":0.000357583729147193,"Topic 28":0.00046067345422246,"Topic 29":0.000230184849881072,"Topic 30":0.00218164798272593,"Topic 31":0.0335155376708238,"Topic 32":0.0439624309075649,"Topic 33":0.0512966247738964,"Topic 34":0.000791265217751107,"Topic 35":0.000277802369759335,"Topic 36":0.000515892277029028,"Topic 37":0.000347441948286526,"Topic 38":0.000592522597991511,"Topic 39":0.00461767678201579,"Topic 40":7.94922891440123e-05,"Topic 41":0.0019118242934843,"Topic 42":0.000433540532130754,"Topic 43":0.000500997889729172,"Topic 44":0.00280707810750233,"Topic 45":0.193661316470597,"Topic 46":8.24167021669039e-05,"Topic 47":0.00146655562048277,"Topic 48":0.0029789361809511,"Topic 49":0.00293647324231483,"Topic 50":0.155440024461554,"Topic 51":0.270534690360901,"Topic 52":0.00523741776955944,"Topic 53":0.0264369216727736,"Topic 54":0.00245796730580814,"Topic 55":0.00435567452604632,"Topic 56":0.00408764903660521,"Topic 57":0.0023190458648239,"Topic 58":0.00224610000110058,"Topic 59":0.00860578351560693,"Topic 60":0.0033995285403017,"Topic 61":0.0200862231658254,"Topic 62":0.000488937967204991},{"id":3,"body":"<div id='rss wrap'>\n<figure class='intro image intro left'><img src='https://cdn.arstechnica.net/wp content/uploads/2017/05/global_seed_vault_mari tefre 800x600.jpg'><p class='caption' style='font size:0.8em'><a href='https://cdn.arstechnica.net/wp content/uploads/2017/05/global_seed_vault_mari tefre.jpg' class='enlarge link' data height='768' data width='1024'>Enlarge</a> (credit: <a rel='nofollow' class='caption link' href='https://www.flickr.com/photos/landbruks _og_matdepartementet/4186766565/'>Mari Tefre/Svalbard Globale fr\u00f8hvelv</a>)</p>  </figure><div><a name='page 1'></a></div>\n<p>In Arctic Svalbard, there is a vault that might sound like a sci fi plot device. Completed in 2008, the <a href='https://www.croptrust.org/our work/svalbard global seed vault/'>Global Seed Vault</a> is a remote archive for safeguarding seeds for thousands of crop varieties. If anything dramatic should happen elsewhere around the world, we want these seeds to be there.</p>\n<p>The vault consists of a giant freezer room bored into a mountain, protected by the bedrock around it and the permafrost above it. But according to a report <em><a href='https://www.theguardian.com/environment/2017/may/19/arctic stronghold of worlds seeds flooded after permafrost melts?CMP=fb_gu'>in The Guardian</a></em>, the vault experienced an unhappy surprise recently\u2014melting permafrost in winter.</p>\n<p>The Arctic just experienced its second warmest winter on record (surpassed only by 2016), and Svalbard saw remarkable temperatures and even rain. In fact, Svalbard <a href='http://climatefeedback.org/evaluation/global quackery earth not warmed past 19 years new study finds joseph curl the daily wire/'>averaged</a> more than 4 \u00b0C above even the 2004 2013 average.</p>\n</div><p><a href='https://arstechnica.com/science/2017/05/the arctic seed vault had to deal with melting permafrost last winter/#p3'>Read 2 remaining paragraphs</a> | <a href='https://arstechnica.com/science/2017/05/the arctic seed vault had to deal with melting permafrost last winter/?comments=1'>Comments</a></p><div class='feedflare'>\n<a href='http://feeds.arstechnica.com/~ff/arstechnica/science?a=Fwd5Xrdusck:KyNAavF g5g:V_sGLiPBpWU'><img src='http://feeds.feedburner.com/~ff/arstechnica/science?i=Fwd5Xrdusck:KyNAavF g5g:V_sGLiPBpWU' border='0'></img></a> <a href='http://feeds.arstechnica.com/~ff/arstechnica/science?a=Fwd5Xrdusck:KyNAavF g5g:F7zBnMyn0Lo'><img src='http://feeds.feedburner.com/~ff/arstechnica/science?i=Fwd5Xrdusck:KyNAavF g5g:F7zBnMyn0Lo' border='0'></img></a> <a href='http://feeds.arstechnica.com/~ff/arstechnica/science?a=Fwd5Xrdusck:KyNAavF g5g:qj6IDK7rITs'><img src='http://feeds.feedburner.com/~ff/arstechnica/science?d=qj6IDK7rITs' border='0'></img></a> <a href='http://feeds.arstechnica.com/~ff/arstechnica/science?a=Fwd5Xrdusck:KyNAavF g5g:yIl2AUoC8zA'><img src='http://feeds.feedburner.com/~ff/arstechnica/science?d=yIl2AUoC8zA' border='0'></img></a>\n</div>","journal":"arstechnica","Topic 1":0.00155193815778483,"Topic 2":0.00598505859520212,"Topic 3":0.734010290151695,"Topic 4":0.000994235628398879,"Topic 5":0.000306766289958976,"Topic 6":0.0194689274780251,"Topic 7":0.000561247746740813,"Topic 8":0.000737467360199314,"Topic 9":0.000664058666084114,"Topic 10":0.0044817303164147,"Topic 11":0.00375509454916954,"Topic 12":0.00299494338269327,"Topic 13":0.000654396191971295,"Topic 14":0.000568082874961813,"Topic 15":0.000184965503232528,"Topic 16":0.000302741846768305,"Topic 17":0.00159759021750039,"Topic 18":0.00109825067971926,"Topic 19":0.00117959552487769,"Topic 20":0.000300154220400358,"Topic 21":0.0128134739986744,"Topic 22":0.000554509905325375,"Topic 23":0.000289629508700389,"Topic 24":0.000490272674073897,"Topic 25":0.000859007812640221,"Topic 26":0.00604285072330345,"Topic 27":0.000172152707341224,"Topic 28":0.000926405913621737,"Topic 29":0.00128188762880995,"Topic 30":0.000913685636309188,"Topic 31":0.000103081416972442,"Topic 32":0.00525785706518539,"Topic 33":0.000843290310911932,"Topic 34":0.00184061252069704,"Topic 35":0.00395880108201952,"Topic 36":0.0108830540716186,"Topic 37":0.000940572799199576,"Topic 38":0.0442531711939193,"Topic 39":0.00695447987829776,"Topic 40":0.00221864215322505,"Topic 41":0.00107312556867152,"Topic 42":0.000986251970640303,"Topic 43":0.000449570143605723,"Topic 44":0.00176889436329174,"Topic 45":0.000188295618584434,"Topic 46":0.0532672369219015,"Topic 47":0.00121813570832872,"Topic 48":0.00497752037141287,"Topic 49":0.000274638762517299,"Topic 50":0.000753424024749204,"Topic 51":0.00440213685713397,"Topic 52":0.00049887959434404,"Topic 53":0.0116678833679372,"Topic 54":0.000493617441558082,"Topic 55":0.00113134986833183,"Topic 56":0.000166161216850263,"Topic 57":0.0104584629873908,"Topic 58":0.000207141359938886,"Topic 59":0.00382978615602492,"Topic 60":0.0161451644883301,"Topic 61":0.00253318076484993,"Topic 62":0.000514168060961191},{"id":4,"body":"<?xml version='1.0' encoding='UTF 8'?><html>\n<body>Nvidia CEO Jen Hsun Huang wants his robocar computer package to become an industry standard<figure>\n<img src='http://spectrum.ieee.org/image/Mjg1MDEyOA.jpeg'/>\n<figcaption>Photo: David Paul Morris/Bloomberg/Getty Images</figcaption>\n</figure>\n<div>\n<p/>\n<p/>\n<p/>\n<p/>\n<p/>\n<p/>\n<p/>\n<p/>\n<p/>\n<p/>\n<p/>\n<p/>\n<p/>\n<p/>\n<p/>\n<p/>\n<p/>\n<p/>\n<p/>\n<p/>\n<p/>\n<p/>\n<p/>\n<p/>\n<p/>\n<p/>\n<p/>\n<p/>\n<p/>\n<p>Jen Hsun Huang, the CEO of Nvidia, said last night in Las Vegas that his company and Audi are developing a self driving car that will finally be worthy of the name. That autonomous vehicle, he said, will be on the roads by 2020.</p>\n<p>Huang made his remarks in a keynote address at CES. Then he was joined by Scott Keough, the head of Audi of America, who emphasized that the car really would drive itself. \u201cWe\u2019re talking highly automated cars, operating in numerous conditions, in 2020,\u201d Keough said. A prototype based on Audi\u2019s Q7 car was, as he spoke, driving itself around the lot beside the convention center, he added.</p>\n<p>This implies the Audi Nvidia car will have \u201c<a shape='rect' href='http://www.sae.org/misc/pdfs/automated_driving.pdf'>Level 4</a>\u201d capability, needing no human being to supervise it or take the wheel on short notice, at least not under \u201cnumerous\u201d road conditions. So, maybe it won\u2019t do cross country moose chases in snowy climes.</p>\n<p>These claims are pretty much in line with what other companies, notably Tesla, have been saying lately. The difference is in the timing: Nvidia and Audi have drawn a hard deadline for three years from now.</p>\n<p>In a statement, Audi said that it would introduce what it called the world's first Level 3 car <span>this year; it will be</span> based on Nvidia computing hardware and software. Level 3 cars can do all the driving most of the time but require that a human be ready to take over.</p>\n<p>At the heart of <a shape='rect' href='http://nvidianews.nvidia.com/news/nvidia audi partner to put world s most advanced ai car on road by 2020'>Nvidia\u2019s strategy</a> is the computational muscle of its graphics processing chips, or GPUs, which the company has honed over decades of work in the gaming industry. Some 18 months ago, <a shape='rect' href='http://spectrum.ieee.org/cars that think/transportation/self driving/nvidia wants to build the robocars brain'>it released</a> its first automotive package, called Drive PX, and today it announced the successor to it, called Xavier. (That Audi in the parking lot uses the older, Drive PX version.)</p>\n<p>\u201c[Xavier] has eight high end CPU cores, 512 of our next gen GPUs,\u201d Huang said.  \u201cIt has the performance of a high end PC shrunk onto a tiny chip, [with] teraflop operation, at just 3o watts.\u201d By teraflop he meant 30 of them: 30 trillion operations per second, 15 times as much as the 2015 machine could handle.</p>\n<p>That power is used in deep learning, the software technique that has transformed pattern recognition and other applications in the past three years. Deep learning uses a hierarchy of processing layers that make sense of a mass of data by organizing it into progressively more meaningful chunks.</p>\n<p>For instance, it might begin in the lowest layer of processing by tracing a line of pixels to infer an edge. It might proceed up to the next layer up by combining edges to construct features, like a nose or an eyebrow. In the next higher layer it might notice a face, and in a still higher one, it might compare that face to a database of faces to identify a person. Presto, and you have facial recognition, a longstanding bugbear of AI.</p>\n<p/>\n<p/>\n<p/>\n<p/>\n<p/>\n<p>And, if you can recognize faces, why not do the same for cars, sign posts, roadsides and pedestrians? Google\u2019s Deep Mind, a pioneer in deep learning, did it for the infamously difficult Asian game of Go last year, when its <a shape='rect' href='http://spectrum.ieee.org/tech talk/computing/networks/alphago wins match against top go player'>Alphago program beat </a>one of the best Go players in the world.</p>\n<p>In Nvidia\u2019s experimental self driving car, dozens of cameras, microphones, speakers, and other sensors are strewn around the outside and also the inside. Reason: Until full autonomy is achieved, the person behind the wheel will still have to stay focused on the road, and the car will see to it that he is.</p>\n<p>\u201cThe car itself will be an AI for driving, but it will also be an AI for codriving\u2014the AI copilot,\u201d Huang said. \u201cWe believe the AI is either driving you or looking out for you. When it is not driving you it is still completely engaged.\u201d</p>\n<p>In a video clip, the car warns the driver with a natural language alert: \u201cCareful, there is a motorcycle approaching the center lane,\u201d it intones. And when the driver\u2014an Nvidia employee named Janine\u2014asks the car to take her home, it obeys her even when street noise interferes. That\u2019s because it actually reads her lips, too (at least for a list of common phrases and sentences).</p>\n<p>Huang cited work at Oxford and at Google\u2019s Deep Mind outfit showing that deep learning can read lips with 95 percent accuracy, which is much better than most human lip readers. In November, <a shape='rect' href='https://news.developer.nvidia.com/lip reading ai more accurate than humans/'>Nvidia announced</a> that it was working on a similar system.</p>\n<p>It would seem that the Nvidia test car is the first machine to emulate the <a shape='rect' href='https://www.youtube.com/watch?v=lj OlW83b6U'>ploy portrayed</a> in <em>2001: A Space Odyssey</em>, in which the HAL 9000 AI read the lips of astronauts plotting to shut the machine down.</p>\n<p>These efforts to supervise the driver so the driver can better supervise the car is directed against Level 3\u2019s main problem: driver complacency. <a shape='rect' style='font family: Georgia, serif; font size: 18px; line height: 25px;' href='http://spectrum.ieee.org/cars that think/transportation/self driving/what next for teslas autopilot'>Many experts believe</a>\n<span> that this is what occurred with the driver of the Tesla Model S that crashed into a truck. Some reports say he failed to override the vehicle\u2019s decision making because he was watching a video.</span>\n</p>\n<p>Last night, Huang also announced deals with other auto industry players. Nvidia is partnering with Japan\u2019s Zenrin mapping company, as it has done with Europe\u2019s TomTom and China\u2019s Baidu. Its robocar computer will be manufactured by ZF, an auto supplier in Europe; commercial samples are already available. And it is also partnering with Bosch, the world\u2019s largest auto supplier.</p>\n<p>Besides these automotive initiatives, Nvidia also announced new directions in gaming and consumer electronics. In March, it will release a cloud based version of its GeForce gaming platform on Facebook that will provide a for fee service through the cloud to any PC loaded with the right client software. This required that latency, the delay in response from the cloud, be reduced to manageable proportions. Nvidia also announced a voice controlled television system based on Google\u2019s Android system.</p>\n<p>The common link among these businesses is Nvidia\u2019s prowess in graphics processing, which provides the computational muscle needed for deep learning. In fact, you might say that deep learning\u2014and robocars\u2014came along at just the right time for the company: It had built up stupendous processing power in the isolated hothouse of gaming and needed a new outlet for it. Artificial intelligence is that outlet.</p>\n<p/>\n<p/>\n<p/>\n<p/>\n<p/>\n<p/>\n<p/>\n<p/>\n<p/>\n<p/>\n<p/>\n</div>\n</body>\n</html>","journal":"ieee","Topic 1":0.00120133213330688,"Topic 2":0.00772769761955348,"Topic 3":0.00482953770621112,"Topic 4":0.000501210541811761,"Topic 5":0.000953271095367049,"Topic 6":0.00282806178084942,"Topic 7":0.0026034807119027,"Topic 8":0.172027175061691,"Topic 9":0.000745294268450523,"Topic 10":0.0351856583675005,"Topic 11":0.00357166160040583,"Topic 12":0.00209886725210161,"Topic 13":0.00723935050469732,"Topic 14":0.000645641690322838,"Topic 15":0.0127498812700921,"Topic 16":0.246936003238549,"Topic 17":0.0160881310446155,"Topic 18":0.000398457401363831,"Topic 19":0.00332254940006493,"Topic 20":0.00983542394526542,"Topic 21":0.00111901618161057,"Topic 22":0.0485896046077585,"Topic 23":0.00791800911422127,"Topic 24":0.011833679461487,"Topic 25":0.106051933296641,"Topic 26":0.0103629562511395,"Topic 27":0.00492342109832293,"Topic 28":0.0142732645696493,"Topic 29":0.00105332910074013,"Topic 30":0.00239041694801574,"Topic 31":0.0320372152472061,"Topic 32":0.0103951927804995,"Topic 33":0.000517218470709121,"Topic 34":0.00396403421955712,"Topic 35":0.00747821499289834,"Topic 36":0.00250761805922738,"Topic 37":0.00290230287327588,"Topic 38":0.00754162417657914,"Topic 39":0.00346616284350489,"Topic 40":0.00150527610223085,"Topic 41":0.00171805334271969,"Topic 42":0.0036307153817933,"Topic 43":0.00424775850126428,"Topic 44":0.0133952472504592,"Topic 45":0.00190888024454791,"Topic 46":0.00101784019967055,"Topic 47":0.00160061512080358,"Topic 48":0.0589164133701976,"Topic 49":0.0137233296347757,"Topic 50":0.00284058676051228,"Topic 51":0.00456585681760395,"Topic 52":0.000888922221131999,"Topic 53":0.00816011972349193,"Topic 54":0.00139592524489406,"Topic 55":0.0228435383223482,"Topic 56":0.000969757997137942,"Topic 57":0.0252348061420062,"Topic 58":0.0045394319814174,"Topic 59":0.000982667467008182,"Topic 60":0.00294112738422335,"Topic 61":0.0113660440162851,"Topic 62":0.000793185846310474}]
